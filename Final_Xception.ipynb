{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff7d0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    " \n",
    "import os\n",
    "import zipfile\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.models import Model, Sequential, load_model\n",
    "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38d3e16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 다운로드 받은 이미지 압축 파일 해제\n",
    "# print(os.listdir(\"./drive/MyDrive\"))\n",
    "local_zip = './train.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./res/train')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = './test.zip'\n",
    "\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('./res/test')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "45062286",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"./res/\"\n",
    "\n",
    "train_dir = \"train/train/\"\n",
    "\n",
    "train_class = ['dog', 'elephant', 'giraffe', 'guitar', 'horse', 'house', 'person']\n",
    "\n",
    "\n",
    "test_dir = \"test/test/0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c31fde1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1698 validated image filenames.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>dogs</th>\n",
       "      <th>elephant</th>\n",
       "      <th>giraffe</th>\n",
       "      <th>guitar</th>\n",
       "      <th>horse</th>\n",
       "      <th>house</th>\n",
       "      <th>person</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train/dog/pic_327.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train/dog/pic_064.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train/dog/pic_037.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train/dog/pic_310.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train/dog/pic_167.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1693</th>\n",
       "      <td>train/person/pic_337.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1694</th>\n",
       "      <td>train/person/pic_160.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1695</th>\n",
       "      <td>train/person/pic_429.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1696</th>\n",
       "      <td>train/person/pic_059.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1697</th>\n",
       "      <td>train/person/pic_389.jpg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1698 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                          path  dogs  elephant  giraffe  guitar  horse  house  \\\n",
       "0        train/dog/pic_327.jpg     1         0        0       0      0      0   \n",
       "1        train/dog/pic_064.jpg     1         0        0       0      0      0   \n",
       "2        train/dog/pic_037.jpg     1         0        0       0      0      0   \n",
       "3        train/dog/pic_310.jpg     1         0        0       0      0      0   \n",
       "4        train/dog/pic_167.jpg     1         0        0       0      0      0   \n",
       "...                        ...   ...       ...      ...     ...    ...    ...   \n",
       "1693  train/person/pic_337.jpg     0         0        0       0      0      0   \n",
       "1694  train/person/pic_160.jpg     0         0        0       0      0      0   \n",
       "1695  train/person/pic_429.jpg     0         0        0       0      0      0   \n",
       "1696  train/person/pic_059.jpg     0         0        0       0      0      0   \n",
       "1697  train/person/pic_389.jpg     0         0        0       0      0      0   \n",
       "\n",
       "      person  \n",
       "0          0  \n",
       "1          0  \n",
       "2          0  \n",
       "3          0  \n",
       "4          0  \n",
       "...      ...  \n",
       "1693       1  \n",
       "1694       1  \n",
       "1695       1  \n",
       "1696       1  \n",
       "1697       1  \n",
       "\n",
       "[1698 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_one_hot = []\n",
    "\n",
    "for path in range(len(train_class)):\n",
    "    for img in os.listdir(base_dir + train_dir + train_class[path]):\n",
    "        class2label = [''] + [0] * len(train_class)\n",
    "        class2label[0] = (train_dir + train_class[path] + \"/\" + img)[6:]\n",
    "        class2label[path + 1] = 1\n",
    "        train_one_hot.append(class2label)\n",
    "\n",
    "        \n",
    "train_answer = pd.DataFrame(train_one_hot, columns = [\"path\", \"dogs\", 'elephant', 'giraffe', 'guitar', 'horse' , 'house', 'person'])\n",
    "train_answer.to_csv('./train_answer.csv', index=False)\n",
    "\n",
    "data = pd.read_csv(\"./train_answer.csv\")\n",
    "columns = data.columns\n",
    "\n",
    "datagen=ImageDataGenerator(\n",
    "      rescale = 1/255,\n",
    "      rotation_range=40,\n",
    "      width_shift_range=0.2,\n",
    "      height_shift_range=0.2,\n",
    "      shear_range=0.2,\n",
    "      zoom_range=0.2,\n",
    "      horizontal_flip=True,\n",
    "      fill_mode='nearest')\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "                                            dataframe=data,\n",
    "                                            directory='./res/train/',\n",
    "                                            x_col=\"path\",\n",
    "                                            y_col=columns[1:],\n",
    "                                            batch_size=32,\n",
    "                                            shuffle=False,\n",
    "                                            class_mode=\"raw\",\n",
    "                                            target_size=(299,299))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72e34beb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"xception\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 299, 299, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1 (Conv2D)           (None, 149, 149, 32) 864         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_bn (BatchNormaliza (None, 149, 149, 32) 128         block1_conv1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv1_act (Activation)   (None, 149, 149, 32) 0           block1_conv1_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2 (Conv2D)           (None, 147, 147, 64) 18432       block1_conv1_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_bn (BatchNormaliza (None, 147, 147, 64) 256         block1_conv2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "block1_conv2_act (Activation)   (None, 147, 147, 64) 0           block1_conv2_bn[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1 (SeparableConv2 (None, 147, 147, 128 8768        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv1_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_act (Activation (None, 147, 147, 128 0           block2_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2 (SeparableConv2 (None, 147, 147, 128 17536       block2_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block2_sepconv2_bn (BatchNormal (None, 147, 147, 128 512         block2_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d (Conv2D)                 (None, 74, 74, 128)  8192        block1_conv2_act[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block2_pool (MaxPooling2D)      (None, 74, 74, 128)  0           block2_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 74, 74, 128)  512         conv2d[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 74, 74, 128)  0           block2_pool[0][0]                \n",
      "                                                                 batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_act (Activation (None, 74, 74, 128)  0           add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1 (SeparableConv2 (None, 74, 74, 256)  33920       block3_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv1_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_act (Activation (None, 74, 74, 256)  0           block3_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2 (SeparableConv2 (None, 74, 74, 256)  67840       block3_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block3_sepconv2_bn (BatchNormal (None, 74, 74, 256)  1024        block3_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 37, 37, 256)  32768       add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "block3_pool (MaxPooling2D)      (None, 37, 37, 256)  0           block3_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 37, 37, 256)  1024        conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 37, 37, 256)  0           block3_pool[0][0]                \n",
      "                                                                 batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_act (Activation (None, 37, 37, 256)  0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1 (SeparableConv2 (None, 37, 37, 728)  188672      block4_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv1_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_act (Activation (None, 37, 37, 728)  0           block4_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2 (SeparableConv2 (None, 37, 37, 728)  536536      block4_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block4_sepconv2_bn (BatchNormal (None, 37, 37, 728)  2912        block4_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 19, 19, 728)  186368      add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block4_pool (MaxPooling2D)      (None, 19, 19, 728)  0           block4_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 19, 19, 728)  2912        conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 19, 19, 728)  0           block4_pool[0][0]                \n",
      "                                                                 batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_act (Activation (None, 19, 19, 728)  0           add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_act (Activation (None, 19, 19, 728)  0           block5_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_act (Activation (None, 19, 19, 728)  0           block5_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block5_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block5_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block5_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 19, 19, 728)  0           block5_sepconv3_bn[0][0]         \n",
      "                                                                 add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_act (Activation (None, 19, 19, 728)  0           add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_act (Activation (None, 19, 19, 728)  0           block6_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_act (Activation (None, 19, 19, 728)  0           block6_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block6_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block6_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block6_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 19, 19, 728)  0           block6_sepconv3_bn[0][0]         \n",
      "                                                                 add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_act (Activation (None, 19, 19, 728)  0           add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_act (Activation (None, 19, 19, 728)  0           block7_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_act (Activation (None, 19, 19, 728)  0           block7_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block7_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block7_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block7_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 19, 19, 728)  0           block7_sepconv3_bn[0][0]         \n",
      "                                                                 add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_act (Activation (None, 19, 19, 728)  0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_act (Activation (None, 19, 19, 728)  0           block8_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_act (Activation (None, 19, 19, 728)  0           block8_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block8_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block8_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block8_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_6 (Add)                     (None, 19, 19, 728)  0           block8_sepconv3_bn[0][0]         \n",
      "                                                                 add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_act (Activation (None, 19, 19, 728)  0           add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv1_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv1_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_act (Activation (None, 19, 19, 728)  0           block9_sepconv1_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv2_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv2_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_act (Activation (None, 19, 19, 728)  0           block9_sepconv2_bn[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3 (SeparableConv2 (None, 19, 19, 728)  536536      block9_sepconv3_act[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block9_sepconv3_bn (BatchNormal (None, 19, 19, 728)  2912        block9_sepconv3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add_7 (Add)                     (None, 19, 19, 728)  0           block9_sepconv3_bn[0][0]         \n",
      "                                                                 add_6[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_act (Activatio (None, 19, 19, 728)  0           block10_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_act (Activatio (None, 19, 19, 728)  0           block10_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block10_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block10_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block10_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_8 (Add)                     (None, 19, 19, 728)  0           block10_sepconv3_bn[0][0]        \n",
      "                                                                 add_7[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_act (Activatio (None, 19, 19, 728)  0           block11_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_act (Activatio (None, 19, 19, 728)  0           block11_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block11_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block11_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block11_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 19, 19, 728)  0           block11_sepconv3_bn[0][0]        \n",
      "                                                                 add_8[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_act (Activatio (None, 19, 19, 728)  0           block12_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv2_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_act (Activatio (None, 19, 19, 728)  0           block12_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3 (SeparableConv (None, 19, 19, 728)  536536      block12_sepconv3_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block12_sepconv3_bn (BatchNorma (None, 19, 19, 728)  2912        block12_sepconv3[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 19, 19, 728)  0           block12_sepconv3_bn[0][0]        \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_act (Activatio (None, 19, 19, 728)  0           add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1 (SeparableConv (None, 19, 19, 728)  536536      block13_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv1_bn (BatchNorma (None, 19, 19, 728)  2912        block13_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_act (Activatio (None, 19, 19, 728)  0           block13_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2 (SeparableConv (None, 19, 19, 1024) 752024      block13_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block13_sepconv2_bn (BatchNorma (None, 19, 19, 1024) 4096        block13_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 10, 10, 1024) 745472      add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block13_pool (MaxPooling2D)     (None, 10, 10, 1024) 0           block13_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 10, 10, 1024) 4096        conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 10, 10, 1024) 0           block13_pool[0][0]               \n",
      "                                                                 batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1 (SeparableConv (None, 10, 10, 1536) 1582080     add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_bn (BatchNorma (None, 10, 10, 1536) 6144        block14_sepconv1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv1_act (Activatio (None, 10, 10, 1536) 0           block14_sepconv1_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2 (SeparableConv (None, 10, 10, 2048) 3159552     block14_sepconv1_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_bn (BatchNorma (None, 10, 10, 2048) 8192        block14_sepconv2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "block14_sepconv2_act (Activatio (None, 10, 10, 2048) 0           block14_sepconv2_bn[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "avg_pool (GlobalAveragePooling2 (None, 2048)         0           block14_sepconv2_act[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "predictions (Dense)             (None, 1000)         2049000     avg_pool[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 22,910,480\n",
      "Trainable params: 22,855,952\n",
      "Non-trainable params: 54,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "xception = tf.keras.applications.Xception(\n",
    "    include_top=True, weights='imagenet',input_shape=(299,299,3), pooling=\"max\")\n",
    "xception.trainable = True # 가중치 학습 여부 설정 (False : 가중치 학습 X)\n",
    "xception.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf634905",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "54/54 [==============================] - 55s 769ms/step\n"
     ]
    }
   ],
   "source": [
    "pretrained_data = xception.predict(train_generator, verbose=1)\n",
    "\n",
    "x_train, x_valid, y_train, y_valid = train_test_split(pretrained_data, data.iloc[:,1:], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a22875e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Please add `keras.layers.InputLayer` instead of `keras.Input` to Sequential model. `keras.Input` is intended to be used by Functional model.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dropout (Dropout)            (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 256)               256256    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 7)                 903       \n",
      "=================================================================\n",
      "Total params: 290,055\n",
      "Trainable params: 290,055\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "model = Sequential(\n",
    "    [Input(1000,),\n",
    "     \n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(256,  activation='relu'),\n",
    "    \n",
    "    Dense(128,  activation='relu'),\n",
    "    \n",
    "    Dense(7,  activation='softmax')\n",
    "    ])\n",
    "model.summary()\n",
    "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\n",
    "\n",
    "mc = tf.keras.callbacks.ModelCheckpoint('xception_model.h5', monitor='val_loss', mode='min', verbose=1, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83403be9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "43/43 [==============================] - 1s 7ms/step - loss: 1.9405 - accuracy: 0.2518 - val_loss: 1.9361 - val_accuracy: 0.2853\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 1.93608, saving model to xception_model.h5\n",
      "Epoch 2/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9271 - accuracy: 0.3078 - val_loss: 1.9243 - val_accuracy: 0.2824\n",
      "\n",
      "Epoch 00002: val_loss improved from 1.93608 to 1.92430, saving model to xception_model.h5\n",
      "Epoch 3/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.9097 - accuracy: 0.3255 - val_loss: 1.9084 - val_accuracy: 0.2882\n",
      "\n",
      "Epoch 00003: val_loss improved from 1.92430 to 1.90836, saving model to xception_model.h5\n",
      "Epoch 4/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8867 - accuracy: 0.3233 - val_loss: 1.8885 - val_accuracy: 0.2853\n",
      "\n",
      "Epoch 00004: val_loss improved from 1.90836 to 1.88847, saving model to xception_model.h5\n",
      "Epoch 5/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8571 - accuracy: 0.3049 - val_loss: 1.8636 - val_accuracy: 0.2824\n",
      "\n",
      "Epoch 00005: val_loss improved from 1.88847 to 1.86358, saving model to xception_model.h5\n",
      "Epoch 6/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.8252 - accuracy: 0.3144 - val_loss: 1.8371 - val_accuracy: 0.2941\n",
      "\n",
      "Epoch 00006: val_loss improved from 1.86358 to 1.83712, saving model to xception_model.h5\n",
      "Epoch 7/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7879 - accuracy: 0.3233 - val_loss: 1.8088 - val_accuracy: 0.3088\n",
      "\n",
      "Epoch 00007: val_loss improved from 1.83712 to 1.80878, saving model to xception_model.h5\n",
      "Epoch 8/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7546 - accuracy: 0.3395 - val_loss: 1.7757 - val_accuracy: 0.3265\n",
      "\n",
      "Epoch 00008: val_loss improved from 1.80878 to 1.77570, saving model to xception_model.h5\n",
      "Epoch 9/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.7045 - accuracy: 0.3697 - val_loss: 1.7354 - val_accuracy: 0.3382\n",
      "\n",
      "Epoch 00009: val_loss improved from 1.77570 to 1.73537, saving model to xception_model.h5\n",
      "Epoch 10/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.6566 - accuracy: 0.4072 - val_loss: 1.6897 - val_accuracy: 0.3500\n",
      "\n",
      "Epoch 00010: val_loss improved from 1.73537 to 1.68974, saving model to xception_model.h5\n",
      "Epoch 11/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.5984 - accuracy: 0.4462 - val_loss: 1.6395 - val_accuracy: 0.4029\n",
      "\n",
      "Epoch 00011: val_loss improved from 1.68974 to 1.63955, saving model to xception_model.h5\n",
      "Epoch 12/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.5502 - accuracy: 0.4809 - val_loss: 1.5885 - val_accuracy: 0.4441\n",
      "\n",
      "Epoch 00012: val_loss improved from 1.63955 to 1.58852, saving model to xception_model.h5\n",
      "Epoch 13/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.4842 - accuracy: 0.5169 - val_loss: 1.5357 - val_accuracy: 0.4676\n",
      "\n",
      "Epoch 00013: val_loss improved from 1.58852 to 1.53569, saving model to xception_model.h5\n",
      "Epoch 14/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.4274 - accuracy: 0.5331 - val_loss: 1.4840 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00014: val_loss improved from 1.53569 to 1.48401, saving model to xception_model.h5\n",
      "Epoch 15/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.3761 - accuracy: 0.5670 - val_loss: 1.4346 - val_accuracy: 0.5265\n",
      "\n",
      "Epoch 00015: val_loss improved from 1.48401 to 1.43461, saving model to xception_model.h5\n",
      "Epoch 16/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.3169 - accuracy: 0.5943 - val_loss: 1.3904 - val_accuracy: 0.5500\n",
      "\n",
      "Epoch 00016: val_loss improved from 1.43461 to 1.39041, saving model to xception_model.h5\n",
      "Epoch 17/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2638 - accuracy: 0.6127 - val_loss: 1.3454 - val_accuracy: 0.5706\n",
      "\n",
      "Epoch 00017: val_loss improved from 1.39041 to 1.34538, saving model to xception_model.h5\n",
      "Epoch 18/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.2087 - accuracy: 0.6311 - val_loss: 1.3047 - val_accuracy: 0.5735\n",
      "\n",
      "Epoch 00018: val_loss improved from 1.34538 to 1.30471, saving model to xception_model.h5\n",
      "Epoch 19/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.1795 - accuracy: 0.6465 - val_loss: 1.2726 - val_accuracy: 0.5941\n",
      "\n",
      "Epoch 00019: val_loss improved from 1.30471 to 1.27264, saving model to xception_model.h5\n",
      "Epoch 20/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 1.1332 - accuracy: 0.6576 - val_loss: 1.2382 - val_accuracy: 0.6059\n",
      "\n",
      "Epoch 00020: val_loss improved from 1.27264 to 1.23818, saving model to xception_model.h5\n",
      "Epoch 21/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0958 - accuracy: 0.6686 - val_loss: 1.2111 - val_accuracy: 0.6029\n",
      "\n",
      "Epoch 00021: val_loss improved from 1.23818 to 1.21106, saving model to xception_model.h5\n",
      "Epoch 22/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0696 - accuracy: 0.6679 - val_loss: 1.1858 - val_accuracy: 0.6059\n",
      "\n",
      "Epoch 00022: val_loss improved from 1.21106 to 1.18575, saving model to xception_model.h5\n",
      "Epoch 23/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0318 - accuracy: 0.6811 - val_loss: 1.1633 - val_accuracy: 0.6147\n",
      "\n",
      "Epoch 00023: val_loss improved from 1.18575 to 1.16335, saving model to xception_model.h5\n",
      "Epoch 24/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 1.0094 - accuracy: 0.6966 - val_loss: 1.1425 - val_accuracy: 0.6294\n",
      "\n",
      "Epoch 00024: val_loss improved from 1.16335 to 1.14249, saving model to xception_model.h5\n",
      "Epoch 25/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9874 - accuracy: 0.7032 - val_loss: 1.1260 - val_accuracy: 0.6324\n",
      "\n",
      "Epoch 00025: val_loss improved from 1.14249 to 1.12599, saving model to xception_model.h5\n",
      "Epoch 26/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9498 - accuracy: 0.7062 - val_loss: 1.1094 - val_accuracy: 0.6324\n",
      "\n",
      "Epoch 00026: val_loss improved from 1.12599 to 1.10940, saving model to xception_model.h5\n",
      "Epoch 27/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9251 - accuracy: 0.7099 - val_loss: 1.0931 - val_accuracy: 0.6412\n",
      "\n",
      "Epoch 00027: val_loss improved from 1.10940 to 1.09313, saving model to xception_model.h5\n",
      "Epoch 28/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9106 - accuracy: 0.7253 - val_loss: 1.0807 - val_accuracy: 0.6412\n",
      "\n",
      "Epoch 00028: val_loss improved from 1.09313 to 1.08074, saving model to xception_model.h5\n",
      "Epoch 29/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.9060 - accuracy: 0.7261 - val_loss: 1.0660 - val_accuracy: 0.6441\n",
      "\n",
      "Epoch 00029: val_loss improved from 1.08074 to 1.06601, saving model to xception_model.h5\n",
      "Epoch 30/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8834 - accuracy: 0.7312 - val_loss: 1.0532 - val_accuracy: 0.6441\n",
      "\n",
      "Epoch 00030: val_loss improved from 1.06601 to 1.05323, saving model to xception_model.h5\n",
      "Epoch 31/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8544 - accuracy: 0.7489 - val_loss: 1.0433 - val_accuracy: 0.6441\n",
      "\n",
      "Epoch 00031: val_loss improved from 1.05323 to 1.04327, saving model to xception_model.h5\n",
      "Epoch 32/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8438 - accuracy: 0.7423 - val_loss: 1.0315 - val_accuracy: 0.6529\n",
      "\n",
      "Epoch 00032: val_loss improved from 1.04327 to 1.03153, saving model to xception_model.h5\n",
      "Epoch 33/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8346 - accuracy: 0.7452 - val_loss: 1.0245 - val_accuracy: 0.6529\n",
      "\n",
      "Epoch 00033: val_loss improved from 1.03153 to 1.02449, saving model to xception_model.h5\n",
      "Epoch 34/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8180 - accuracy: 0.7511 - val_loss: 1.0170 - val_accuracy: 0.6559\n",
      "\n",
      "Epoch 00034: val_loss improved from 1.02449 to 1.01701, saving model to xception_model.h5\n",
      "Epoch 35/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.8026 - accuracy: 0.7555 - val_loss: 1.0128 - val_accuracy: 0.6559\n",
      "\n",
      "Epoch 00035: val_loss improved from 1.01701 to 1.01275, saving model to xception_model.h5\n",
      "Epoch 36/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7858 - accuracy: 0.7607 - val_loss: 0.9994 - val_accuracy: 0.6559\n",
      "\n",
      "Epoch 00036: val_loss improved from 1.01275 to 0.99936, saving model to xception_model.h5\n",
      "Epoch 37/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7652 - accuracy: 0.7754 - val_loss: 0.9958 - val_accuracy: 0.6559\n",
      "\n",
      "Epoch 00037: val_loss improved from 0.99936 to 0.99581, saving model to xception_model.h5\n",
      "Epoch 38/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.7611 - accuracy: 0.7680 - val_loss: 0.9927 - val_accuracy: 0.6618\n",
      "\n",
      "Epoch 00038: val_loss improved from 0.99581 to 0.99266, saving model to xception_model.h5\n",
      "Epoch 39/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7543 - accuracy: 0.7673 - val_loss: 0.9824 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00039: val_loss improved from 0.99266 to 0.98239, saving model to xception_model.h5\n",
      "Epoch 40/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7396 - accuracy: 0.7725 - val_loss: 0.9792 - val_accuracy: 0.6588\n",
      "\n",
      "Epoch 00040: val_loss improved from 0.98239 to 0.97920, saving model to xception_model.h5\n",
      "Epoch 41/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7314 - accuracy: 0.7695 - val_loss: 0.9744 - val_accuracy: 0.6647\n",
      "\n",
      "Epoch 00041: val_loss improved from 0.97920 to 0.97437, saving model to xception_model.h5\n",
      "Epoch 42/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7435 - accuracy: 0.7644 - val_loss: 0.9697 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00042: val_loss improved from 0.97437 to 0.96969, saving model to xception_model.h5\n",
      "Epoch 43/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7115 - accuracy: 0.7813 - val_loss: 0.9625 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00043: val_loss improved from 0.96969 to 0.96253, saving model to xception_model.h5\n",
      "Epoch 44/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.7012 - accuracy: 0.7769 - val_loss: 0.9633 - val_accuracy: 0.6706\n",
      "\n",
      "Epoch 00044: val_loss did not improve from 0.96253\n",
      "Epoch 45/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6857 - accuracy: 0.7872 - val_loss: 0.9574 - val_accuracy: 0.6735\n",
      "\n",
      "Epoch 00045: val_loss improved from 0.96253 to 0.95737, saving model to xception_model.h5\n",
      "Epoch 46/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6947 - accuracy: 0.7747 - val_loss: 0.9543 - val_accuracy: 0.6765\n",
      "\n",
      "Epoch 00046: val_loss improved from 0.95737 to 0.95429, saving model to xception_model.h5\n",
      "Epoch 47/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6669 - accuracy: 0.7923 - val_loss: 0.9512 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00047: val_loss improved from 0.95429 to 0.95118, saving model to xception_model.h5\n",
      "Epoch 48/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6648 - accuracy: 0.7865 - val_loss: 0.9470 - val_accuracy: 0.6824\n",
      "\n",
      "Epoch 00048: val_loss improved from 0.95118 to 0.94698, saving model to xception_model.h5\n",
      "Epoch 49/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6600 - accuracy: 0.7909 - val_loss: 0.9456 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00049: val_loss improved from 0.94698 to 0.94557, saving model to xception_model.h5\n",
      "Epoch 50/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6371 - accuracy: 0.8034 - val_loss: 0.9417 - val_accuracy: 0.6941\n",
      "\n",
      "Epoch 00050: val_loss improved from 0.94557 to 0.94173, saving model to xception_model.h5\n",
      "Epoch 51/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6524 - accuracy: 0.7909 - val_loss: 0.9416 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00051: val_loss improved from 0.94173 to 0.94156, saving model to xception_model.h5\n",
      "Epoch 52/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6337 - accuracy: 0.7982 - val_loss: 0.9402 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00052: val_loss improved from 0.94156 to 0.94017, saving model to xception_model.h5\n",
      "Epoch 53/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6278 - accuracy: 0.8004 - val_loss: 0.9375 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00053: val_loss improved from 0.94017 to 0.93752, saving model to xception_model.h5\n",
      "Epoch 54/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6186 - accuracy: 0.8078 - val_loss: 0.9355 - val_accuracy: 0.6853\n",
      "\n",
      "Epoch 00054: val_loss improved from 0.93752 to 0.93551, saving model to xception_model.h5\n",
      "Epoch 55/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6150 - accuracy: 0.8034 - val_loss: 0.9337 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00055: val_loss improved from 0.93551 to 0.93373, saving model to xception_model.h5\n",
      "Epoch 56/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.6128 - accuracy: 0.8041 - val_loss: 0.9297 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00056: val_loss improved from 0.93373 to 0.92968, saving model to xception_model.h5\n",
      "Epoch 57/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.6153 - accuracy: 0.8063 - val_loss: 0.9301 - val_accuracy: 0.6882\n",
      "\n",
      "Epoch 00057: val_loss did not improve from 0.92968\n",
      "Epoch 58/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5969 - accuracy: 0.8152 - val_loss: 0.9265 - val_accuracy: 0.6912\n",
      "\n",
      "Epoch 00058: val_loss improved from 0.92968 to 0.92646, saving model to xception_model.h5\n",
      "Epoch 59/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5862 - accuracy: 0.8240 - val_loss: 0.9240 - val_accuracy: 0.6912\n",
      "\n",
      "Epoch 00059: val_loss improved from 0.92646 to 0.92400, saving model to xception_model.h5\n",
      "Epoch 60/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5783 - accuracy: 0.8181 - val_loss: 0.9246 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00060: val_loss did not improve from 0.92400\n",
      "Epoch 61/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5731 - accuracy: 0.8137 - val_loss: 0.9220 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00061: val_loss improved from 0.92400 to 0.92196, saving model to xception_model.h5\n",
      "Epoch 62/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5774 - accuracy: 0.8159 - val_loss: 0.9227 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00062: val_loss did not improve from 0.92196\n",
      "Epoch 63/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5667 - accuracy: 0.8166 - val_loss: 0.9206 - val_accuracy: 0.7000\n",
      "\n",
      "Epoch 00063: val_loss improved from 0.92196 to 0.92061, saving model to xception_model.h5\n",
      "Epoch 64/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5646 - accuracy: 0.8130 - val_loss: 0.9190 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00064: val_loss improved from 0.92061 to 0.91901, saving model to xception_model.h5\n",
      "Epoch 65/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5599 - accuracy: 0.8203 - val_loss: 0.9181 - val_accuracy: 0.6971\n",
      "\n",
      "Epoch 00065: val_loss improved from 0.91901 to 0.91813, saving model to xception_model.h5\n",
      "Epoch 66/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5363 - accuracy: 0.8402 - val_loss: 0.9210 - val_accuracy: 0.7029\n",
      "\n",
      "Epoch 00066: val_loss did not improve from 0.91813\n",
      "Epoch 67/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5561 - accuracy: 0.8225 - val_loss: 0.9208 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00067: val_loss did not improve from 0.91813\n",
      "Epoch 68/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5402 - accuracy: 0.8240 - val_loss: 0.9182 - val_accuracy: 0.7059\n",
      "\n",
      "Epoch 00068: val_loss did not improve from 0.91813\n",
      "Epoch 69/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5459 - accuracy: 0.8211 - val_loss: 0.9165 - val_accuracy: 0.7029\n",
      "\n",
      "Epoch 00069: val_loss improved from 0.91813 to 0.91649, saving model to xception_model.h5\n",
      "Epoch 70/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5346 - accuracy: 0.8343 - val_loss: 0.9165 - val_accuracy: 0.7118\n",
      "\n",
      "Epoch 00070: val_loss did not improve from 0.91649\n",
      "Epoch 71/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.5379 - accuracy: 0.8196 - val_loss: 0.9163 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00071: val_loss improved from 0.91649 to 0.91633, saving model to xception_model.h5\n",
      "Epoch 72/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5268 - accuracy: 0.8328 - val_loss: 0.9157 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00072: val_loss improved from 0.91633 to 0.91575, saving model to xception_model.h5\n",
      "Epoch 73/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5178 - accuracy: 0.8365 - val_loss: 0.9149 - val_accuracy: 0.7088\n",
      "\n",
      "Epoch 00073: val_loss improved from 0.91575 to 0.91492, saving model to xception_model.h5\n",
      "Epoch 74/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5112 - accuracy: 0.8351 - val_loss: 0.9180 - val_accuracy: 0.7118\n",
      "\n",
      "Epoch 00074: val_loss did not improve from 0.91492\n",
      "Epoch 75/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.5003 - accuracy: 0.8336 - val_loss: 0.9153 - val_accuracy: 0.7118\n",
      "\n",
      "Epoch 00075: val_loss did not improve from 0.91492\n",
      "Epoch 76/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4894 - accuracy: 0.8557 - val_loss: 0.9143 - val_accuracy: 0.7265\n",
      "\n",
      "Epoch 00076: val_loss improved from 0.91492 to 0.91426, saving model to xception_model.h5\n",
      "Epoch 77/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4869 - accuracy: 0.8483 - val_loss: 0.9127 - val_accuracy: 0.7235\n",
      "\n",
      "Epoch 00077: val_loss improved from 0.91426 to 0.91268, saving model to xception_model.h5\n",
      "Epoch 78/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4885 - accuracy: 0.8402 - val_loss: 0.9155 - val_accuracy: 0.7206\n",
      "\n",
      "Epoch 00078: val_loss did not improve from 0.91268\n",
      "Epoch 79/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4904 - accuracy: 0.8498 - val_loss: 0.9165 - val_accuracy: 0.7176\n",
      "\n",
      "Epoch 00079: val_loss did not improve from 0.91268\n",
      "Epoch 80/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4815 - accuracy: 0.8527 - val_loss: 0.9165 - val_accuracy: 0.7176\n",
      "\n",
      "Epoch 00080: val_loss did not improve from 0.91268\n",
      "Epoch 81/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4804 - accuracy: 0.8417 - val_loss: 0.9173 - val_accuracy: 0.7235\n",
      "\n",
      "Epoch 00081: val_loss did not improve from 0.91268\n",
      "Epoch 82/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4767 - accuracy: 0.8542 - val_loss: 0.9173 - val_accuracy: 0.7176\n",
      "\n",
      "Epoch 00082: val_loss did not improve from 0.91268\n",
      "Epoch 83/100\n",
      "43/43 [==============================] - 0s 5ms/step - loss: 0.4912 - accuracy: 0.8446 - val_loss: 0.9183 - val_accuracy: 0.7235\n",
      "\n",
      "Epoch 00083: val_loss did not improve from 0.91268\n",
      "Epoch 84/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4612 - accuracy: 0.8520 - val_loss: 0.9164 - val_accuracy: 0.7147\n",
      "\n",
      "Epoch 00084: val_loss did not improve from 0.91268\n",
      "Epoch 85/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4699 - accuracy: 0.8439 - val_loss: 0.9171 - val_accuracy: 0.7294\n",
      "\n",
      "Epoch 00085: val_loss did not improve from 0.91268\n",
      "Epoch 86/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4677 - accuracy: 0.8446 - val_loss: 0.9178 - val_accuracy: 0.7176\n",
      "\n",
      "Epoch 00086: val_loss did not improve from 0.91268\n",
      "Epoch 87/100\n",
      "43/43 [==============================] - 0s 4ms/step - loss: 0.4585 - accuracy: 0.8490 - val_loss: 0.9170 - val_accuracy: 0.7353\n",
      "\n",
      "Epoch 00087: val_loss did not improve from 0.91268\n",
      "Epoch 00087: early stopping\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f96d030efa0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=Adam(1e-4), metrics=['accuracy']) # 최적화 함수 학습률 1e-4에서 0.001로 변경\n",
    "model.fit(x_train, y_train, epochs=100, batch_size=32, validation_data=(x_valid, y_valid),callbacks=[es,mc])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d4072a64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "xception (Functional)        (None, 1000)              22910480  \n",
      "_________________________________________________________________\n",
      "sequential (Sequential)      (None, 7)                 290055    \n",
      "=================================================================\n",
      "Total params: 23,200,535\n",
      "Trainable params: 23,146,007\n",
      "Non-trainable params: 54,528\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "loaded_model = load_model('xception_model.h5')\n",
    " \n",
    "final_model = Sequential([xception, model])\n",
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "48bb514b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 350 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_df = pd.DataFrame()\n",
    "test = glob.glob(\"./res/test/test/0/*.jpg\")\n",
    "test.sort()\n",
    "test_dir = []\n",
    "for img in test:\n",
    "    test_dir.append(img[11:])\n",
    "test_df[\"path\"] = test_dir\n",
    " \n",
    "test_datagen=ImageDataGenerator(rescale = 1/255)\n",
    "test_generator = test_datagen.flow_from_dataframe(  dataframe=test_df[:],\n",
    "                                                    directory='./res/test/',\n",
    "                                                    x_col=\"path\",\n",
    "                                                    y_col=columns[0],\n",
    "                                                    batch_size=1,\n",
    "                                                    shuffle=False,\n",
    "                                                    class_mode=\"raw\",\n",
    "                                                    target_size=(299,299))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4211eb8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350/350 [==============================] - 18s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "pred = final_model.predict(test_generator, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a764137",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>answer value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>345</th>\n",
       "      <td>345</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>346</th>\n",
       "      <td>346</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>347</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>348</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>349</th>\n",
       "      <td>349</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>350 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0  answer value\n",
       "0             0             2\n",
       "1             1             3\n",
       "2             2             3\n",
       "3             3             3\n",
       "4             4             6\n",
       "..          ...           ...\n",
       "345         345             1\n",
       "346         346             6\n",
       "347         347             3\n",
       "348         348             6\n",
       "349         349             2\n",
       "\n",
       "[350 rows x 2 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer = np.array([y.argmax() for y in pred])\n",
    "test_df = pd.read_csv(\"./test_answer_sample_.csv\")\n",
    "test_df.iloc[:,1] = answer\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fef808de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv('xception_50.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53494499",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2.5 on Python 3.8 & CUDA 11.3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
